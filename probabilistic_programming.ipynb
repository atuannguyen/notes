{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming\n",
    "\n",
    "In this summary, we will look at probabilistic programming language, some inference methods that are commonly used in the field, and some \n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Probabilistic programming language, by definition, is a programming language with the added abilities to sample values from probability distribution and condition values of random variables via observations (e.g. to infer the posterior of a latent variable given the observations).\n",
    "\n",
    "Therefore, in the application of Machine Learning, Probabilistic Programming is to Probabilistic Machine Learning as Automated Differentiation is to Deep Learning. This means that, while Automated Differentiation (e.g. Pytorch, Tensorflow) helps us solve the optimization problem quickly in Deep Learning, Probabilistic Programming hleps us solve the inference problem more conveniently in Probabilistic Machine Learning. ***If we can encode the data generating process of a neural network by a program in a probabilistic programming language, we can then infer the posterior of the network's parameters given the observed data.***\n",
    "\n",
    "Informally, we can think of a probabilistic program as a probabilistic model with latent variables $z$ (usually called sample) and observed variables $x$ (usually called observe). The latent variables $z$ may contain any random variables that are used in the generation of $x$ but not observed together with $x$. More broadly speaking, $z$ may also include some parameters of the generative program (e.g. font size of the captcha). The observe $x$ is usually the output of the program, and is ovserved. The joint probability of the generative program is often denoted by $p(x,z)=p(z)p(x|z)$. With the ability to condition values of random variables via observation, we can infer the posterior distribution $p(z|x)$. Each framework might have different inference methods, and we will explore some of those in the next part.\n",
    "\n",
    "Note that, in probabilistic programming, we often need to have the exact generative model (coded by the probablistic programming language), or at least a simulator that is closed enough to the real generative process. A upside of this is that we can theoretically infinite (synthetic) data pair of $z$ and $x$ (by running the program repeatedly). For example, for solving the captcha, we might need to write a program that output captchas that are very similar to the ones we want to solve. From that, we can obtain as many data point as we want for the learning/inference problem.\n",
    "\n",
    "It is also worth noting that this construction is similar to that of a Variational Auto-Encoder (VAE). In VAE, we also asume a generative process that include $x$ and $z$; however, we don't know the exact generative model. Therefore, VAE learns the generation process by $p_\\theta(x,z)$ so that the marginal $p_\\theta(x)$ is closed to the density of $x$ (which we observed by samples) and learns an approximate inference $q_\\phi(z|x)$. Note that unlike the case of probabilistic program, in VAE, we only have access to a limited number of observations of $x$ (not the pair $(z,x)$).\n",
    "\n",
    "In probabilistic programming language, an execuation of a program is often represented by its trace $(z_t,a_t,i_t)_{t=1}^T$ where $z_t,a_t,i_t$ are respectively the sample value, address, and instance (call number) of the $t^{th}$ entry. The joint distribution $p(x,z)$ of this trace where $x=(x_1,x_2,...,x_N)$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(x,z) &= p(z)p(x|z) \\\\\n",
    "&= \\prod_{t=1}^T f_{a_t}(z_t|z_{1:t-1}) \\prod_{n=1}^N g_n(x_n|z_{1:\\tau(n)})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "where $f_{a_t}$ is is the probability distribution specified by the sample statement (sample of the latent variable $z_t$) at address $a_t$, $g_n$ is the probability distribution of the $n^{th}$ observe statement, and $\\tau(n)$ is the index of the last sample $z_i$ before observing $x_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference methods\n",
    "\n",
    "By defination, for a probabilistic programming language, we need to be able make the inference $p(z|x)$. Different frameworks have different methods to do so, and we will discuss some of them here.\n",
    "\n",
    "First of all, by \"doing the inference of $p(z|x)$\", we often mean to successfully samples from this distribution. When we have its samples, we can estimate its density or an expectation over it by using these sample (Monte Carlo). Now, note that:\n",
    "\n",
    "\\begin{equation}\n",
    "p(z|x) = \\frac{p(x|z)p(z)}{p(x)} \\quad\\text{      (Bayes' rule)}\n",
    "\\end{equation}\n",
    "\n",
    "Asumming that both the prior of $z$ $p(z)$ and the likelihood $p(x|z)$ are well defined, $p(x|z)p(z)$ is easy to compute. However, the marginal $p(x)$ is intractable. In other words, we only have the unnormalized density function. Fortunately, we still have methods to draw samples from this unnormalized density. Two widely used methods in the literature are Markov Chain Monte Carlo (MCMC) and Importance Sampling (IS).\n",
    "\n",
    "- Markov Chain Monte Carlo:\n",
    "    MCMC is a method to asymptotically sample from a desired distribution. The idea of MCMC is to sample repeatedly from a markov chain which has a stationary distribution and whose stationary distribution is the desired distribution. MCMC methods are to construct for us such markov chain. Popular MCMC methods are Metropolis Hastings, Lagrangian Dynamics and Hamiltonian Monte Carlo. However, samples from MCMC are not i.i.d. (as a direct consequence from a markov chain which a new sample depends on the last sample). Moreover, since we only use a finite number of samples in practice, these samples are not from the true distribution of interest. Therefore, the function estimator obtained by MCMC is always biased (unlike other methods such as rejection sampling or importance sampling).\n",
    "\n",
    "- Important Sampling:\n",
    "    IS is a method to approximate the density function of a distribution $p(z)$ or an expectation of a function over the distribution, with a proposal $q(z)$. Asume that we only have the unnormalized pdf $p'(z)$ of $p(z)$ (i.e. $p(z)=\\frac{p'(z)}{\\int p'(z') dz'}$).\n",
    "    \n",
    "    For example, we have:\n",
    "    \\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\mathbb{E}_{p(z)}[f(z)] &= \\int f(z)p(z)dz\\\\\n",
    "    &= \\int f(z)\\frac{p(z)}{q(z)}q(z)dz\\\\\n",
    "    &= \\mathbb{E}_{q(z)}[f(z)\\frac{p(z)}{q(z)}]\\\\\n",
    "    &= \\frac{1}{\\int p'(z)dz}\\mathbb{E}_{q(z)}[f(z)\\frac{p'(z)}{q(z)}]\n",
    "    \\end{split}\n",
    "    \\end{equation}\n",
    "    \n",
    "    Let $z_1,z_2,...,z_S$ be samples from $q(z)$ and the weight $m_i=\\frac{p'(z_i)}{q(z_i)}$ then\n",
    "\n",
    "    \\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\int p'(z)dz = \\mathbb{E}_{q(z)}[\\frac{p'(z)}{q(z)}] &\\approx \\frac{\\sum_{i=1}^{S} m_i}{S}\\\\\n",
    "    \\mathbb{E}_{q(x)}\\left[f(x)\\frac{p'(x)}{q(x)}\\right] &\\approx \\frac{\\sum_{i=1}^S f(x_i)m_i}{S}\\\\\n",
    "    \\\\\n",
    "    \\implies\\mathbb{E}_{p(x)}[f(x)] &\\approx \\sum_{i=1}^S f(x_i)w_i\n",
    "    \\end{split}\n",
    "    \\end{equation}\n",
    "\n",
    "    where $w_i=\\frac{m_i}{\\sum_{i=1}^{S} m_i}$, which is the normalized version of $m_i$.\n",
    "    \n",
    "    Note that this estimator might have very high variance, due to the fact that $m_i$ might be unbounded (consider the case where $q$ and $p$ have density mass distributed in different area). Using such estimator with high variance can lead to an erroneous approximation. To reduce the variance, we need to choose a proposal $q$ that is closed to $p$. In the setting of probabilistic programming (to infer $p(z|x)$), a natural choice of $q$ could be the prior $p(z)$, since the posterior would be somewhat close the the prior, due to the Bayes' rule. However, in a high dimensional latent space (and the curse of dimensionality), using the prior might not be optimal. Some methods, including Inference Compilation, have been developed to choose better proposal.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference Compilation\n",
    "\n",
    "The idea of Inference Compilation is to learn a proposal $q_\\phi(z|x)$, via a neural network parameterized by $\\phi$, to use for the importance sampling estimator above. To reduce the variance of the estimator, we need "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
